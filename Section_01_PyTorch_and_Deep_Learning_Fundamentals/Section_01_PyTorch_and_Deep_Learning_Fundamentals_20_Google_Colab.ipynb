{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpH3llhzR7xq"
      },
      "source": [
        "După cum spuneam, Utilizând un MacBook nu putem să utilizăm și un GPU pentru a experimenta tot ce ține de partea de CPU și GPU utilizând PyTorch. De asta o să utilizăm `Google Colab` pentru a utiliza un GPU oferit gratis de către ei. În acest notebook o să recapitulăm cum putem verifica dacă avem disponibil un GPU, câte GPU-uri avem la dispoziție și cum să mutăm un tensor de pe CPU pe GPU și invers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9yFBdHs3Rio5"
      },
      "outputs": [],
      "source": [
        "# importing the library\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN_GJpAeSilR"
      },
      "source": [
        "Acuma o să verificăm dacă avem la dispozițite o placă video pe care să o folosim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or8g6mXLRnUw",
        "outputId": "dc2da87c-12cf-43dd-bfd7-713d29b5acab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# verifying if there is a GPU available\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCG2NVsqTAI4"
      },
      "source": [
        "Din moment ce avem returnat 'True' asta înseamnă că avem la dispoziție un GPU pe care am putea să îl utilizăm. O să creem acea variabilă **device** acuma prin care o să precizăm să folosim placa grafică dacă este disponibilă, iar dacă aceasta nu este disponibilă o să folosim un procesor (CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hdh-s0-9Rwa8",
        "outputId": "d21337e6-be3e-41ed-a2bc-7ffb547f577f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KvPBbSUThFQ"
      },
      "source": [
        "'cuda' înseamnă că avem la dispoziție un GPU și putem să îl folosim. O să verificăm acuma și numărul de GPU pe care îl avem la dispoziție"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk0VUDAKTdc3",
        "outputId": "8b3c7430-453f-4d54-fc3c-1d787328514a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFrUey29TvDg"
      },
      "source": [
        "O singură placă video avem la dispoziție, dar putem să ne utilizăm de aceasta pentru a exeprimenta. Următorul pas pe care o să îl facem, o să creem un tensor. După cum spuneam atunci când creem un tensor, acesta se creează automat pe CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrArHgY1Tski",
        "outputId": "9377b0f4-e3a4-49b3-b1bd-4dbb72e6f393"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = torch.tensor([1,2, 3])\n",
        "tensor, tensor.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RQLXwT8UJ7s"
      },
      "source": [
        "Atunci când creem tensor, putem să îi specificăm în momentul în care îl creem dacă să fie creat pe CPU sau pe GPU prin utilizarea argumentului `device` în momentul în care îl creem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKPxDFF_UICm",
        "outputId": "e08f6606-5c61-4c4a-af2b-0d0ca695697c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), device(type='cpu'))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2 = torch.tensor([1, 2, 3], device='cpu')\n",
        "tensor2, tensor2.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7CmyV5VU-BT"
      },
      "source": [
        "O să trecem acuma la partea în care o să trecem un tensor de pe CPU pe GPU. Știm că putem să facem asta utilizând comanda 'torch.Tensor.to()' căruia îi specificăm device-ul pe care dorim să mutăm tensor-ul respectiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CdxL5B8xUkG8"
      },
      "outputs": [],
      "source": [
        "tensor_on_gpu = tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbpopeAvVQ6K",
        "outputId": "b7cba3f4-6bd9-4872-c071-fb8b470a3a5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3], device='cuda:0'), device(type='cuda', index=0))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu, tensor_on_gpu.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7EjRkN2VWam"
      },
      "source": [
        "Din moment ce am avut la dispoziție un GPU și am mutat un tensor de pe CPU pe GPU, acuma când accesăm atributul de **device** acesta ne afișează faptul că acum acest tensor se află acuma pe o placă grafică. De asemnea ne este returnat și index-ul acelei plăci grafice care este util în momentul în care lucrăm cu mai multe plăci grafice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dEUtBu-VzOm"
      },
      "source": [
        "În continuare o să încercăm să transformăm un tensor care este pe GPU într-un array din NumPy pentru a vedea cum arată și altă eroare comună din PyTorch, și anumea cea în care **tensorii nu se găsesc pe același device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "yMn5WezGVUDb",
        "outputId": "de6bbaea-9f6e-4a9f-9a90-fbccc5151890"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7d1f4cc01529>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor_on_gpu_to_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "tensor_on_gpu_to_numpy = tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTnFAKM_WKyG"
      },
      "source": [
        "După cum se poate observa, când încercăm să transformăm un tensor ce se găsește pe GPU într-un array din NumPy avem o eroare care ne spune că nu putem converti un tensor ce se găsește pe GPU într-un array de NumPy. Din fericire, PyTorch ne afișează și rezolvarea acestei erori, și anume trebuie să utilizăm metoda `torch.Tensor.cpu()` pentru a muta un tensor înapoi pe CPU, iar abia după putem să îl convertim într-un array de NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKQhY9D2WJFS",
        "outputId": "1a0b1a73-99b8-4bf5-8c48-2b4d68d50d74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu_to_numpy = tensor_on_gpu.cpu().numpy()\n",
        "tensor_on_gpu_to_numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIGF9h7oW1q1"
      },
      "source": [
        "Putem să vedem că acuma am reușit să transformăm acel tensor într-un array din NumPy după ce l-am mutat de pe GPU pe CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21oeHZHGXPvY"
      },
      "source": [
        "Cam așa arată codul și funcționează atunci când avem la dispoziție un GPU pe care să îl folosim."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
