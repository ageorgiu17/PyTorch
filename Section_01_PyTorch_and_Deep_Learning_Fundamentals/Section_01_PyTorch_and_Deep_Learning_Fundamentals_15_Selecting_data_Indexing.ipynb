{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data - Indexing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data trecută ne-am uitat peste anumite modalități prin care putem modifica shape-ul unui tensor, iar această necesitate de a modifica forma pe care o are un tensor vine din apariția extrem de deasă a erorii care ne duce către forma pe care o are un anumit tensor. O să facem o scurtă recapitulare a acestor metode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------RESHAPING----------\n",
      "Initail tensor shape: torch.Size([9])\n",
      "Reshaped tensor shape: torch.Size([1, 9])\n",
      "Reshaped tensor v2 shape: torch.Size([3, 3])\n",
      "\n",
      "----------VIEW----------\n",
      "Original tensor shape: torch.Size([9])\n",
      "View tensor shape: torch.Size([1, 1, 9])\n",
      "A view shares the same memory as the tensor, any modification in the view will modify the tensor\n",
      "\n",
      "----------STACKING----------\n",
      "tensor to be stacked: \n",
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor stacked 4 times vertically: \n",
      "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "tensor stacked 4 times horizontally: \n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [8., 8., 8., 8.],\n",
      "        [9., 9., 9., 9.]])\n",
      "\n",
      "----------SQUEEZING----------\n",
      "Original tensor before squeezing shape: torch.Size([1, 1, 9])\n",
      "Squeezed tensor after squeezing shape: torch.Size([9])\n",
      "\n",
      "----------UNSQUEEZING----------\n",
      "Original tensor before unsqueezing shape: torch.Size([9])\n",
      "Unsqueezed tensor after unsqueezing shape: torch.Size([9, 1])\n",
      "\n",
      "----------PERMUTE----------\n",
      "Original tensor shape: torch.Size([244, 212, 3])\n",
      "Permuted tensor shape: torch.Size([3, 244, 212])\n"
     ]
    }
   ],
   "source": [
    "# importing PyTorch\n",
    "import torch\n",
    "\n",
    "# creating tensor to work with\n",
    "tensor = torch.arange(1., 10.)\n",
    "\n",
    "# reshaping tensors\n",
    "print(f'\\n----------RESHAPING----------')\n",
    "print(f'Initail tensor shape: {tensor.shape}')\n",
    "print(f'Reshaped tensor shape: {tensor.reshape(1, 9).shape}')\n",
    "print(f'Reshaped tensor v2 shape: {tensor.reshape(3, 3).shape}')\n",
    "\n",
    "\n",
    "# creating a view of a tensor\n",
    "print(f'\\n----------VIEW----------')\n",
    "print(f'Original tensor shape: {tensor.shape}')\n",
    "print(f'View tensor shape: {tensor.view(1, 1, 9).shape}')\n",
    "print(f'A view shares the same memory as the tensor, any modification in the view will modify the tensor')\n",
    "\n",
    "# stacking tensors\n",
    "print(f'\\n----------STACKING----------')\n",
    "print(f'tensor to be stacked: \\n{tensor}')\n",
    "print(f'tensor stacked 4 times vertically: \\n{torch.stack([tensor, tensor, tensor, tensor], dim=0)}')\n",
    "print(f'tensor stacked 4 times horizontally: \\n{torch.stack([tensor, tensor, tensor, tensor], dim=1)}')\n",
    "\n",
    "# squeezing tensors\n",
    "tensor1 = tensor.reshape(1, 1, 9)\n",
    "print(f'\\n----------SQUEEZING----------')\n",
    "print(f'Original tensor before squeezing shape: {tensor1.shape}')\n",
    "print(f'Squeezed tensor after squeezing shape: {tensor1.squeeze().shape}')\n",
    "\n",
    "# unsqueezing tensors\n",
    "print(f'\\n----------UNSQUEEZING----------')\n",
    "print(f'Original tensor before unsqueezing shape: {tensor.shape}')\n",
    "print(f'Unsqueezed tensor after unsqueezing shape: {tensor.unsqueeze(dim=1).shape}')\n",
    "\n",
    "# permuting tensors\n",
    "print(f'\\n----------PERMUTE----------')\n",
    "image_tensor = torch.rand(244, 212, 3)\n",
    "print(f'Original tensor shape: {image_tensor.shape}')\n",
    "print(f'Permuted tensor shape: {image_tensor.permute(2, 0, 1).shape}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În lecția curentă o să vedem cum putem să accesăm date dintr-un tensor folosind partea de `indexare` din Python. Partea de indexare atunci când lucrăm cu tensori multidimensionali poate fi destul de complicată la început. O să creem un tensor cu trei dimensiuni pentru a putea face partea practică cât mai bine. Indexarea la tenosri se face asemenea cu indexarea din NumPy, iar pentru accesarea elementelor de asemenea se folosește setul de paranteze drepte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim, tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avem tensorul de mai sus, iar pe baza acestui tensor o să lucrăm. Tensorul repectiv are trei dimensiuni, prima având un element, iar restul câte trei elemente. Putem să începem să utilizăm setul de paranteze drepte pentru a realiza indexarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([3, 3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0].ndim, tensor[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă utilizăm un set de paranteze drepte, acestea o să reprezinte prima dimensiune din cadrul acestui tensor, pentru a accesa următoarele dimensiuni putem să mai utilizăm încă un set de paranteze drepte (atâtea seturi de paranteze drepte câte dimensiuni avem). Dacă pentru valoare de la indexare alegem o valoare care depășește limita acelei dimensiuni o să primim o eroare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tensor[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing the first dimension\n",
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing the first and second dimensions\n",
    "tensor[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing the first, second and third dimension\n",
    "tensor[0][1][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O altă modalitate de a utiliza parte de indexare pe o matrice cu mai multe dimensiuni este să utilizăm toate valorile de indexare într-un singur set de parantezse drepte. Acest lucră o să arate cam așa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deși metoda de indexare este diferită, rezultatul este același. Prima metodă (**tensor[0][0]**) este metoda standard din Python, iar metoda a doua (**tensor[0, 0]**) este metoda utilizată în NumPy. Avantajul folosirii metodei din NumPy este faptul că putem să utilizăm și slicing la acest tip de indexare. Adică atunci când dorim să extragem să zicem toate valorile de la primul element (neinclus) spre final, putem utiliza partea de indexare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizând partea de indexare am reușit să extragem din a doua dimensiune toate valorile aflate după primul rând de valori, ceea ce cu indexarea standard din Python nu putem să facem. O să scriem o serie de exerciții pe care este indicat să le rezolvăm pentru a putea înțelege mai bine cum funcționează partea de indexare pentru tensori (utilizând stilul din NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values from 0th and 1st dimensions, but only index 1 from 2nd dimension\n",
    "tensor[:, :, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum se poate observa, prin codul de mai sus am extras toate valorile de pe coloana de mijloc, lucru care cu indexarea standard din Python nu puteam să facem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values from 0th dimension, but only index 1 from 1st and 2nd dimension\n",
    "tensor[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "tensor[0, 0, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the 9 value from the tensor\n",
    "tensor[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the all elements from the last dimension of the tensor\n",
    "tensor[:, :, 2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În lecția curentă am învățat următoarele:\n",
    "\n",
    "1. Există două tipuri de indexare pentru tensor\n",
    "\n",
    "    - Indexare standard din Python\n",
    "\n",
    "    - Indexare din NumPy\n",
    "\n",
    "2. Cum să indexăm din prima dimensiune a unui tensor\n",
    "\n",
    "    ```python\n",
    "    import torch\n",
    "\n",
    "    tensor = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "    tensor[0] # indexing for the 0th dimension --> both Python style and NumPy style\n",
    "    ```\n",
    "\n",
    "3. Cum să indexăm din a doua dimensiune a unui tensor\n",
    "\n",
    "    ```python\n",
    "    import torch\n",
    "\n",
    "    tensor = torch.arange(1,10).reshape(1, 3, 3)\n",
    "    tensor[0][1] # indexing for the 0the and 1st dimension --> Python style\n",
    "    tensor[0, 1] # indexing for the 0the and 1st dimension --> NumPy style\n",
    "    ```\n",
    "\n",
    "4. Cum să idexăm după a treia dimensiune a unui tensor\n",
    "\n",
    "    ```python\n",
    "    import torch\n",
    "\n",
    "    tensor = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "    tensor[0][0][2] # indexing for the 0the and 1st dimension --> Python style\n",
    "    tensor[0, 0, 2] # indexing for the 0the and 1st dimension --> NumPy style\n",
    "    ```\n",
    "\n",
    "5. Care este diferența dintre indexarea din Python și cea utilizată în NumPy\n",
    "\n",
    "Indexarea din NumPy ne permite să utilizăm și conceptul de slicing pentru a extrage doar anumite secțiuni dintr-o dimensiune, ceea ce stiul obișnuit de indexare din Python nu ne permite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
