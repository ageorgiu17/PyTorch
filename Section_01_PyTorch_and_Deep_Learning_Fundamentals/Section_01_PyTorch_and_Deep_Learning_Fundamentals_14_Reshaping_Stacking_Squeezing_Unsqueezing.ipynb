{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping, stacking, squeezing and unsqueezing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În ultima parte am văzut cum putem să utilizăm funcțiile de agregare pentru tensori (să aflăm valoarea cea mai mare, cea mai mică, media, suma, etc.). Dintre aceste metode, cea de **mean()** este diferită deoarece această funcționează doar cu date de tip float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------MAX----------\n",
      "tensor(91)\n",
      "tensor(91)\n",
      "----------MIN----------\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "----------ARGMAX----------\n",
      "tensor(9)\n",
      "tensor(9)\n",
      "----------ARGMIN----------\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "----------SUM----------\n",
      "tensor(460)\n",
      "tensor(460)\n",
      "----------MEAN----------\n",
      "tensor(46.)\n",
      "tensor(46.)\n"
     ]
    }
   ],
   "source": [
    "# importing PyTorch\n",
    "import torch\n",
    "\n",
    "tensor = torch.arange(1, 100, 10)\n",
    "\n",
    "# finding the max and min\n",
    "print('----------MAX----------')\n",
    "print(torch.max(tensor))\n",
    "print(tensor.max())\n",
    "\n",
    "print('----------MIN----------')\n",
    "print(torch.min(tensor))\n",
    "print(tensor.min())\n",
    "\n",
    "print('----------ARGMAX----------')\n",
    "# finding the index of max and min\n",
    "print(torch.argmax(tensor))\n",
    "print(tensor.argmax())\n",
    "\n",
    "print('----------ARGMIN----------')\n",
    "print(torch.argmin(tensor))\n",
    "print(tensor.argmin())\n",
    "\n",
    "print('----------SUM----------')\n",
    "# finding the sum\n",
    "print(torch.sum(tensor))\n",
    "print(tensor.sum())\n",
    "\n",
    "print('----------MEAN----------')\n",
    "# finding the mean\n",
    "# we need to modify the datatype for this\n",
    "print(torch.mean(tensor.type(torch.float32)))\n",
    "print(tensor.type(torch.float32).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei lecții o să ne uităm peste anumite metode din PyTorch prin care putem să modificăm forma sau dimensiunea unui tensor deoarece una dintre cele mai comune erori primite din Deep Learning are legătură cu forma pe care o are un tensor, iar din acest motiv trebuie să înțelegem cum am putea să modificăm forma pe care o are un tensor pentru a rezolva problema. Metodele peste care o să ne uităm sunt următoarele:\n",
    "\n",
    "1. Reshaping = modifică forma unui tensor după o formă pe care o definim\n",
    "\n",
    "2. View = returnează un view (precum în SQL) al unui tensor de input cu o formă pe care o definim, dar păstrează același loc în memorie precum tensor-ul original\n",
    "\n",
    "3. Stacking = combină mai mulți tensori adăugându-i fie pe verticală (vstack) fie pe orizontală (hstack)\n",
    "\n",
    "4. Squeezing = elimină toate dimesniunile de tip **1** dintr-un tensor\n",
    "\n",
    "5. Unsqueezing = adaugă o dimensiune de tip **1** la un tensor\n",
    "\n",
    "6. Permute = retunrează un view pentru input-ul oferit cu dimensiuni permutate (schimbate) într-un anumit mod"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toate metodele de mai sus au într-un anumit mod rolul de a modifica forma (shape-ul) și dimensiune (ndim) unui tensor. O să începem prin a crea un tensor și a vedea cum putem utiliza aceste metode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.arange(1., 10.)\n",
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să începem cu metoda `reshape()`. Acestui tensor de mai sus o să încercăm să îi mai atribuim încă o dimensiune. Tensor-ul de mai sus are un singur set de paranteze drepte, prin urmare o singură dimensiune. O să îcercăm să modificăm acest tensor de tip vector (cum este acuma) într-un tensor de tip matrice (să îi mai adăugăm o dimensiune extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 7]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tensor\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, \u001b[39m7\u001b[39;49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 7]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "tensor.reshape(1, 7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eroarea de mai sus apare deoarece încercăm să înghesuim nouă elemente (câte are tensor-ul) într-un nou tensor care are forma de (1, 7), formă care poate conține doar 7 elemente, din acest motiv apare eroarea respectivă. Regula pe care trebuie să o urmăm atunci când facem reshape este cea cum că forma pe care o oferim la reshape să fie compatibilă cu forma inițială. Dacă înlocuim acel 7 cu un 9, atunci o să putem face resape la acel element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.reshape(1, 9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Care este diferența dintre acest tensor și cel iniția? Diferența este la dimensiunea acestui tensor și la forma pe care o are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor ndim: 1\n",
      "Original tensor shape: torch.Size([9])\n",
      "Reshaped tensor ndim: 2\n",
      "Reshaped tensor shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "print(f'Original tensor ndim: {tensor.ndim}')\n",
    "print(f'Original tensor shape: {tensor.shape}')\n",
    "\n",
    "print(f'Reshaped tensor ndim: {tensor.reshape(1, 9).ndim}')\n",
    "print(f'Reshaped tensor shape: {tensor.reshape(1, 9).shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem vedea că acestui tensor i s-a mai adăugat încă o dimensiune. Tensor-ul inițial are nouă elemente, prin urmare putem să îi facem un reshape cu un tensor care are tot nouă elemente (pe câte dimensiuni dorim). O să îi facem un reshape pe două dimensiuni, având forma (3, 3), deoarece 3x3=9, numărul de elemente care sunt prezente în tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.reshape(3, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să trecem acuma la `view`. Un view se creează cum se face partea de **reshape()**, o să îi oferim o nouă formă compatibilă cu tensor-ul asupar căruia aplicăm această metodă, diferența dintre 'reshape' și 'view' este faptul că un 'view' împarte aceeași memorie cu tensor-ul de bază."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = tensor.view(3, 3)\n",
    "view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce efect are acest fapt? Atunci când modificăm valoarea de la 'view' se modifică și tensor-ul inițial deoarece împart aceeași memorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "view[0][0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am modificat prima valoare din variabila 'view', dar din moment ce aceasta împarte aceeași memorie, atunci se modifică și tensor-ul inițial. Mai departe o să trecem la procedeul de `stacking`. Acest procedeu combină mai mulți tensor fie pe verticală, fie pe orizontală. Regula care stăm la baza acestei metode este faptul că acești tensor trebui să aibă aceeași formă și dimensiune. Există mai multe modalități de a combina tensori, iar aceste modalități se specificăm prin modificarea parametrului de `dim`. Acesta este setat inițial la 0, dar putem să îi modificăm valoarea pentru a vedea ce rezultate (sau erori) produce. Modul prin care trebuie să specificăm tensorii pe care dorim să îi combinăm este printr-o listă."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([tensor, tensor, tensor, tensor], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([tensor, tensor, tensor, tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mstack([tensor, tensor, tensor, tensor], dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "torch.stack([tensor, tensor, tensor, tensor], dim=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrul **dim=0** o să facă după cum putem vedea o combinare verticală a acestor tensori, iar **dim=1** realizează combinarea tensorilor pe orizontală. Tensor-ul cu care am lucrat nu ne permită să creem un tensori combinat cu valoarea **dim=2**, dbin cauza formei și dimensiunii pe care o are acesta. Ca să înțelegem cât mai bine cum funcționează `torch.stack()` fie cătuăm documentații pe internet despre acest subiect, fie mai exeprimentăm cu diferite valori pentru forma și dimensiunea unui tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În continuare o să ne utiăm peste comanda `torch.squeeze()`, comandă care elimină toate dimensiunile de valoare 1 (single dimension) dintr-un tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_reshaped = tensor.reshape(1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să lucrăm cu acest tensor pentru care am făcut 'reshape'. Tensor-ul de mai sus are valoarea 2 pentru tensor_reshaped.ndim și valoarea (1, 9) ca și formă. Ce o să se întâmple atunci când utilizăm comanda `tensor.squeeze()`? Definiția acestei metode ne spune că șterge toate dimensiunile cu valoare 1 dintr-un tensor. Tensor-ul de mai sus are două dimensiuni, a câte 1 și 9 elemente, prin urmare, dacă aplicăm această metodă ar trebui să ne șteargă dimensiunea cu valoarea 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshaped.squeeze().shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din output-ul de mai sus reiese ceea ce se spune în definiție, se poate observa faptul că acum tensor-ul are doar o dimensiune de 9 elemente, dimensiunea cu 1 element a fost ștearsă"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Squeezed tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(f'Original tensor: {tensor_reshaped}')\n",
    "print(f'Squeezed tensor: {tensor_reshaped.squeeze()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se poate observa fapul că la tensor-ul la care am aplicat metoda `squeeze()` îi lipsește un set de paranteze drepte (îi lipsește o dimensiune). În ceea ce privește partea de `unsqueeze()`, această metodă adaugă o dimensiune cu valoarea 1 la tensor-ul pentru care apelăm această metodă. O să salvăm rezultatul de la la metoda de **squeeze*()** într-un tensor și după o să ne folosim de acel tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_tensor = tensor_reshaped.squeeze()\n",
    "squeezed_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acestui tensor o să îi mai adăugăm acuma o dimensiune de valaorea 1. Pentru asta, la metoda de `tensor.unsqueeze()` trebuie să îi oferim parametrul **dim**, iar ca și valoare să îi oferim zona unde dorim să punem această dimensiune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_tensor.unsqueeze(dim=0), squeezed_tensor.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_tensor.unsqueeze(dim=1), squeezed_tensor.unsqueeze(dim=1).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultima metodă la care o să ne uităm o să fie cea de `torch.permute()`, iar aceasta ne permită să rearanjăm dimensiunile unui anumit tensor. Dacă avem un tensor cu valoarea (3, 2) la dimensiuni, cu metoda `torch.permute()` putem să modificăm tensor-ul astfel încât forma acestuia să fie (2, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să creem un tensor random care are forma de (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2698, 0.8419],\n",
      "        [0.0867, 0.8942],\n",
      "        [0.4671, 0.0929]])\n",
      "tensor.shape = torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 2)\n",
    "print(tensor)\n",
    "print(f'tensor.shape = {tensor.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca să modificăm shape-ul din (3, 2) în (2, 3) o să utilizăm metoda `permute()`. Acestei metode trebuie să îi oferim ca și valori index-urile pe care se găsesc cele două dimensiuni ale tensor-ului. Dimensiunea cu 3 elemente se găsește pe index-ul 0, iar cea cu două, pe index-ul 1. Aceste două valori trebuie să le oferim metodei respective. Ordinea în care le oferim o să reprezinte nouă ordine a dimensiunilor. Dacă oferim valorile în ordinea (0, 1), atunci nu am modificat nimic deoarece dimensiunea de pe index-ul 0 rămâne tot pe index-ul 0. Ca să facem o modificare trebuie să oferim acele valori în altă ordine ordinea care este disponibilă este (1, 0), adică dimensiunea de pe index-ul 0 al tensor-ului oferit ca și input acum o să fie pe index-ul 1 al noului tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: \n",
      "tensor([[0.2698, 0.8419],\n",
      "        [0.0867, 0.8942],\n",
      "        [0.4671, 0.0929]])\n",
      "tensor shape: torch.Size([3, 2])\n",
      "\n",
      " permuted tensor: \n",
      "tensor([[0.2698, 0.0867, 0.4671],\n",
      "        [0.8419, 0.8942, 0.0929]])\n",
      "permuted tensor shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f'tensor: \\n{tensor}')\n",
    "print(f'tensor shape: {tensor.shape}')\n",
    "print(f'\\n permuted tensor: \\n{tensor.permute(1, 0)}')\n",
    "print(f'permuted tensor shape: {tensor.permute(1, 0).shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Această operațiune de permutare aprare de cele mai multe ori la prelucrarea de imagini, și anume la modificare locației dimensinulor în ceea ce privește color channels. Uneori încărcăm o imagine sub forma (244, 244, 2) ->(height, width, color_channels) și trebuie să avem datele în formatul (3, 244, 244) -> (color_channels, height, width). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a random tensor with dimensions and size as an image\n",
    "image_shape_tensor = torch.rand(224, 224, 3) # [height, width, color_channels]\n",
    "\n",
    "# permuting the dimensions of the tensor\n",
    "permuted_image_shape_tensor = image_shape_tensor.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor as image: torch.Size([224, 224, 3])\n",
      "Permuted tensor as image: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(f'Original tensor as image: {image_shape_tensor.shape}')\n",
    "print(f'Permuted tensor as image: {permuted_image_shape_tensor.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei secțiuni am învățat următoarele:\n",
    "\n",
    "1. Cum să facem reshape la forma unui tensor\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.arange(1., 10.)\n",
    "# the tensor has 9 elements, we only can reshape it to a tensor that also has nine elements (in whatever dimensions)\n",
    "tensor.reshape(1, 9)\n",
    "tensor.reshape(9, 1)\n",
    "tensor.reshape(3, 3)\n",
    "```\n",
    "\n",
    "   - Forma din reshape trebuie să fie compatibilă cu forma tensorului inițial\n",
    "\n",
    "\n",
    "2. Cum să creem un view pentru un tensor (aici putem să îi modificăm și shape-ul tensorului)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.arange(1., 10.)\n",
    "view_tensor = tensor.view(3, 3)\n",
    "```\n",
    "- Diferența dintre reshape și view este faptul că un view împarte aceeași memorie cu tensor-ul inițial, prin urmare orice modificare se va face în view o să apară și în tensor-ul inițial\n",
    "\n",
    "3. Cum să facem stack la mai mulți vectori\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.arange(1., 10.)\n",
    "\n",
    "v_stacked_tensors = torch.stack([tensor, tensor, tensor, tensor], dim=0) # vstack\n",
    "h_stacked_tensors = torch.stack([tensor, tensor, tensor, tensor], dim=1) # hstack\n",
    "```\n",
    "\n",
    "- Tensorii din torch.stack() trebuie să aibă aceeași formă\n",
    "\n",
    "4. Cum să facem squeeze la un tensor\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.rand(size=(1, 9))\n",
    "squeezed_tensor = tensor.squeeze() # removes the 1 dimension from the tensor\n",
    "```\n",
    "\n",
    "5. Cum să facem unsqueeze la un tensor\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.arange(1., 10.)\n",
    "unsqueezed_tensor = tensor.unsqueeze(dim=0)\n",
    "unsqueezed_tensor = tensor.unsqueeze(dim=1)\n",
    "```\n",
    "\n",
    "6. Cum să facem permute la un tensor\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.rand(size=(244, 244, 3))\n",
    "permuted_tensor = tensor.permute(2, 0, 1)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
