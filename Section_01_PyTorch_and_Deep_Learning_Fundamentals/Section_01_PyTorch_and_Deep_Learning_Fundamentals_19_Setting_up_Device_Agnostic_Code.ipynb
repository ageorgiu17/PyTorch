{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Device Agnostic Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca și o recapitulare, în partea trecută am învățat cum putem să verificăm disponibilitatea unui GPU pe sistemul pe care lucrăm și cum putem să setăm un cod să ruleze pe un GPU dacă acesta este disponibil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying is there is a GPU available\n",
      "GPU availability: False\n",
      "\n",
      "Total number of available GPUs\n",
      "Number of available GPUs: 0\n",
      "\n",
      "Setting up the device depending on GPU availability\n",
      "Code running on : cpu\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import torch\n",
    "\n",
    "# verifying if there is a GPU available\n",
    "print('Verifying is there is a GPU available')\n",
    "print(f'GPU availability: {torch.cuda.is_available()}')\n",
    "\n",
    "# printing the total number of available GPUs\n",
    "print('\\nTotal number of available GPUs')\n",
    "print(f'Number of available GPUs: {torch.cuda.device_count()}')\n",
    "\n",
    "# setting up the device depending on GPU availability\n",
    "print('\\nSetting up the device depending on GPU availability')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(F\"Code running on : {device}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă avem un GPU disponibil, putem să punem tensori pe acel GPU (tensori sau modele). Dorim să facem acest lucru deoarece calculele pe un GPU sunt mai rapide, iar astfel putem să facem un speed up la codul pe care îl utilizăm pentru a crea un model. Atunci când creem un tensor, în mod default acesta o să fie creat pe CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a verifica pe ce dispozitiv se găsește un tensor o să ne folosim de atributul `torch.Tensor.device`. Acest atribut o să returneze fie **'cpu'**, fie **'cuda'** în fucție de disponibilitatea unui GPU pe sistemul pe care rulează codul respectiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch** ne pune la dispoziție o metodă extrem de simplă de a muta un tensor de pe un device pe alt device. Pentru a face asta, asupra unui tensor o să aplicăm metoda `tensor.to()`. Ca și argument o să îi atribuim device-ul pe care dorim să mutăm aceast tensor. Pentru început o să setăm din nou acel cod prin care îi atribuim o valoare variabilei 'device' în funcție de disponibilitatea unui GPU în sistemul în care rulăm acest cod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă un tensor se găsește pe un GPU și dorim să îl transformăm într-un array de NumPy, din păcate NumPy nu poate face computații pe GPU, ci doar pe CPU. Din această cauză trebuie să mutăm din nou tensor-ul pe CPU înainte a îl transforma într-un array din NumPy. Pentru acest pas, asupar tensor-ului care se găsește pe GPU o să aplicăm metoda `tensor.cpu()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei lecții am învățat următoarele lucruri:\n",
    "\n",
    "1. Cum să mutăm un tensor de pe CPU pe GPU\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tensor.to(device)\n",
    "```\n",
    "\n",
    "2. Dacă avem un tensor pe GPU și dorim să îl transformăm într-un array din NumPy trebuiue să îl punem pe CPU deoarece NumPy nu poate avea array-uri pe GPU\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1,2, 3])\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_to_numpy = tensor.cpu().numpy()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note!` Deoarece am rulat acest cod pe un MacBook, Apple nu suportă partea de GPU, prin urmare nu am reușit să mutăm tensori de pe CPU pe GPU, toți tensorii din acest tutorial au fost creație pe CPU. Pentru a putea utiliza și înțelege mai bine cum funcționează și partea de GPU o să ne folosim de `Google Colab` pentru a putea utiliza un GPU (putem utiliza acest GPU pe gratis, fără costuri). Modalitatea respectivă este cea mai simplă de utilizat pentru a primi acces la un GPU și a rula cod pe acesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
