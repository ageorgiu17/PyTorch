{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a PyTorch model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul lecții precedente am învățat cum anume putem să salvăm un model de PyTorch dacă suntem mulțumiți cu performanța acestuia. Salvarea modelului ne scutește de crearea unui nou model și de antrenarea acestuia, aceasta păstrânduși hyperparametrii și valorile acestora în momentul în care a fost salvat. După cum s-a văzut, putem salva un model de PyTorch utilizând metoda **torch.save()** căreia îi oferim ca și valoare *state_dict()* modelului și un path către locația unde dorim să salvăm acel model. Pentru a funcția corect, modelul trebuie salvat cu extensia **.pth**\n",
    "\n",
    "    - torch.save(model_0.state_dict(), './models/01_pytorch_workflow_model_01.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din moment ce am salvat modelul acela în cadrul memoriei calculatorului, acuma putem să facem load la acel model și să îl folosim pentru a face predicții cu el. Pentru a face load la un model o să ne folosim de metoda `torch.load()`. Această metodă deserializează tensorii pe CPU și abia apoi sunt mutați înapoi pe device-ul pe care au fost salvați. Este important de reținut asta deoarece dacă salvăm un model cu tensori de GPU, atunci când îi facem load la model, acesta o să conțină aceași tensori tot pe GPU (asta în cazul în care se dispune de GPU)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În lecția precedentă am salvat doar state_dict() ce îl are modelul (adică doar informațiile de pe model), nu modelul în sine. Asta înseamnă că prima dată trebuie să ne creem o instanță a unui model și abia după să facem load la acest state_dict() ca să fie suprascris peste modelul nou creat. În continuare  o să ne creem același model cu care am tot lucrat, o să ne creme o instanță a modelului după care o să rescriem acel state_dict(). Rescriere se va face cu metoda `torch.nn.Modul.load_state_dict()`. În cadrul acestei metode trebuie să apelăm metoda `torch.load()` căreia să îi oferim ca și argument path-ul către modelul salvat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "\n",
    "    # all models should inherite from nn.Module\n",
    "    # all models should overwrite the __init__() method\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "\n",
    "    # overwriting the forward() method\n",
    "    # all models should overwrite this method\n",
    "    def forward(self, x):\n",
    "        # this is the method where the computation is made\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of the model\n",
    "# setting the random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# creating an instance of the model\n",
    "model_0 = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the state_dict() of the model\n",
    "model_0.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am creat noul model observăm faptul că valorile parametrilor sunt cele care s-au creat inițial. Modelul cu care am lucrat în lecția precedentă, după antrenare avea valorile parametrilor mai apropiate de valorile adevărate (acele variabile de weight și bias pe care le-am creat pentru a ne forma setul de date). Putem să facem load la acei parametrii la acest model pentru a ajunge din nou la acele valori, astfel încât să nu mai fim nevoiți să reantrenăm modelul respectiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.load_state_dict(torch.load('./models/01_PyTorch_Workflow_model_01.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rezultatul comenzii de mai sus este \"All keys matched successfully\", ceea ce înseamnă că valorile parametrilor au fost suprascrise. Ca să verificăm asta putem să printăm din nou state_dict() ce îl are modelul acuma după ce s-a făcut load la aceste date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([0.6990])), ('bias', tensor([0.3093]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum se poate observa, valorile acestor parametrii sunt acuma mult mai apropiate de valorile reale, sunt defapt valorile parametrilor ale modelului antrenat din lecția precedentă. Am reușit să ajungem la aceleași valori fără a mai reantrena modelul."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare\n",
    "\n",
    "În secțiunea curentă an învățat cum putem să facem load la state_dict() pe care l-am salvat anterior la o nouă instanță a modelului.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "model_0.load_state_dict(torch.load(PATH_TO_SAVED_STATE_DICT))\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
