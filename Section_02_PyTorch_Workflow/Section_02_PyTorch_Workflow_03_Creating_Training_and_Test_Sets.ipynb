{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training and test sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În partea anterioară am aflat care este formula pentru regresia liniară și cum putem să ne folosim de această formulă pentru a ne crea un set de date liniar cu care să lucrăm pe parcursul acestei secțiuni. O să recrem acest set de date pentru o scurtă recapitulare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the library\n",
    "import torch\n",
    "\n",
    "# Linear Regression formula\n",
    "# y = weight * X + bias\n",
    "\n",
    "# creating variables\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Creating the features\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "\n",
    "# Creating the labels\n",
    "y = weight * X + bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În acest moment avem datele cu care să lucrăm, dar datele sunt toate într-o variabilă. După cum spuneam, un model de Machine Learning sau Deep Learning învață din anumite date și face predicții la un set de date. Datele din care învață și cele pe care face predicții trebuie să fie separate. Din acest motiv o să împărțim datele în `training set` și `test set`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Split | Purpose | Amount of total data | How often is it used? |\n",
    "| --- | --- | --- | --- |\n",
    "| Training set | The model learns from this data (like the course materials you study during the semester) | ~60-80% | Always |\n",
    "| Validation set | The model gets tuned on this data (like the practice exam you take before the final exam). | ~10-20% | Often but not always\n",
    "| Testing set | The model gets evaluated on this data to test what it has learned (like the final exam you take at the end of the semester). | ~10-20% | Always"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mai sus avem cele trei cateorgorii de seturi de date cu care se lucrează în Machine Learning. La fiecare dintre ele avem o descriere despre ce anume reprezintă, cât la sută din numărul total de date se folosește pentru acel set de date și cât de des se utilizează setul de date respectiv. Din acest tabel putem să vedem că setul de validare (**validation set**) nu se folosește chiar mereu. Și noi o să ne creem un doar un **training set** și un **test set** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În continuare cu datele ce le avem o să creem un set de date de antrenare și de testare. O să creem aceste seturi de date utilizând indexare pentru moment (am putea să utilizăm train_test_split din Scikit-Learn, dar pentru a urmări cursul o să folosim partea de indexare). O să ne creem un training set care conține 80% din numărul total de date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "train_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mai sus am aplicat formula prin care am văzut ce număr de date reprezintă 80% din numărul total de date. Modelul nostru o să se antreneze pe cele 40 de date care provin din X, iar în funcție de pattern-urile pe care le găsește acolo o să încerce să facă predicții pentru ultimele 10 elemente din X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mai sus avem cele două seturi de date de antrenare și de testare. Modaliatea pe care am folosit-o este cea mai simplă deoarece setul de date este unul extrem de simplu. Pe parcursul acestui curs o să ne folosim și de Scikit-Learn pentru a face această separare de date."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei secțiuni am învățat următoarele lucruri:\n",
    "\n",
    "1. Care sunt cele trei seturi de date din Machine Learning\n",
    "\n",
    "    - Training set (se folosește mereu și reprezintă 60%-80% din totalul de date)\n",
    "\n",
    "    - Test set (se folosește mereu și reprezintă 10%-20% din totalul de date)\n",
    "\n",
    "    - Validation set (se folosește doar uneori și reprezintă 10%-20% din totalul de date)\n",
    "\n",
    "2. Cum putem face split la setul mare de date\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
